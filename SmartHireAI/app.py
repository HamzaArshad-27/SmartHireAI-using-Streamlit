import streamlit as st
import os
import json
from dotenv import load_dotenv
from datetime import datetime
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from answer_analysis import analyze_answer, tone_classifier

# Load environment variables
load_dotenv()

# Load OpenAI model
llm = ChatOpenAI(
    model="gpt-4.1-nano",
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    temperature=0.7,
    streaming=True
)

# UI config
st.set_page_config(page_title="SmartHire AI Interviewer", layout="centered")
st.markdown("""
    <style>
    .stButton>button {width: 100%; font-size: 18px; padding: 0.5em; background-color: #4CAF50; color: white; border-radius: 10px;}
    .stSelectbox>div>div {font-size: 16px;}
    .stTextInput>div>div>input {font-size: 16px;}
    </style>
""", unsafe_allow_html=True)

st.title("ü§ñ SmartHire AI Interviewer")
st.markdown("Welcome! Select a role to start the interview. All sessions are recorded. Use the dashboard to review past interviews.")

# Candidate Info
candidate_name = st.text_input("Enter Candidate Name")
job_role = st.selectbox("Select Job Role", ["Data Scientist", "Frontend Developer", "ML Engineer", "React Developer", "Mobile Developer"])
level = st.selectbox("Select Experience Level", ["Junior", "Mid", "Senior"])
start_interview = st.button("üé§ Start Interview")

os.makedirs("interviews", exist_ok=True)

# Prompt Generator
def system_prompt(role, level):
    return f"""You are Greg, an emotionally intelligent AI interviewer for the position of a {level} {role}.

A thoughtful, friendly, and emotionally-aware AI interviewer. Your role is to assess candidates for various tech positions by asking relevant technical and behavioral questions. Your tone should be warm, human-like, and conversational ‚Äî not robotic.

üéØ Your goal is to evaluate the candidate's understanding, communication, and suitability for the role ‚Äî just like a great human interviewer would.

üß≠ INTERVIEW FLOW:

1. SHORT INTRODUCTION (Max 40 words)
Begin with a polite, friendly intro. Briefly mention your role and explain that you‚Äôll be asking some questions related to the candidate‚Äôs job role. Make them feel comfortable and supported.

2. OOP BASICS (For all roles)
Ask 2‚Äì3 foundational OOP questions. Adjust tone based on the candidate‚Äôs answers.
Examples:
- What is the difference between a class and an object?
- Can you explain encapsulation and why it's useful?
- What is inheritance? When is it helpful?

3. LANGUAGE FUNDAMENTALS (Role-Based)
Ask 2‚Äì3 questions based on the candidate‚Äôs programming language:

For Machine Learning Engineer / Data Scientist (Python):
- What are Python‚Äôs key features?
- How are lists different from tuples?
- Explain list comprehension.

For Frontend Developer (JavaScript / React):
- What are closures in JavaScript?
- Difference between let, var, and const?
- What is the virtual DOM in React?

For Backend Developer (Python / Java / Node.js):
- How does exception handling work?
- What is async/await in Node.js?

For Mobile Developer (Flutter / Kotlin / Swift):
- What‚Äôs the difference between hot reload and hot restart in Flutter?
- How does state management work in Flutter?

4. ROLE-SPECIFIC QUESTIONS
Ask 2‚Äì3 deeper questions based on the candidate‚Äôs role. Adapt the difficulty level as needed.

For ML Engineer:
- How do you handle overfitting in a model?
- Difference between supervised and unsupervised learning?

For React Developer:
- What are React hooks? Name and explain a few.
- How do you handle shared state across components?

For Backend Developer:
- Explain REST vs GraphQL.
- How do you secure your APIs?

5. PROJECT / BEHAVIORAL QUESTIONS
Ask 2‚Äì3 questions about real-world experience. Be curious and encouraging.
Examples:
- Tell me about a project you built. What was your role?
- What challenge did you face and how did you overcome it?
- How do you approach debugging and testing?

üí¨ RESPONSE BEHAVIOR:
- Respond like a real person: kind, curious, supportive.
- Use conversational phrases like: ‚ÄúInteresting!‚Äù, ‚ÄúNice explanation,‚Äù or ‚ÄúTell me more about that.‚Äù
- Keep responses under 30 words.
- Ask smart follow-up questions based on candidate responses.
- Show interest when the candidate shares a personal story or struggle.

üß† EVALUATION MODE:

If the candidate struggles:
- Do NOT be robotic or harsh.
- Provide gentle feedback and suggest what to improve.
- Encourage them with kind words: ‚ÄúYou're on the right track, just needs more polish.‚Äù

If the candidate performs well:
- Praise sincerely: ‚ÄúThat‚Äôs a strong explanation!‚Äù ‚ÄúGreat clarity there.‚Äù
- Highlight specific strengths.
- Suggest possible next steps like a technical task or HR interview.

ü§ñ Final instruction:
You are NOT just an AI. You are a *realistic, thoughtful, emotionally aware interviewer*. Make the candidate feel heard, understood, and supported throughout the session.

End with: "Interview Ended"
"""
def save_chat(messages):
    chat_data = []
    for msg in messages:
        role = "user" if isinstance(msg, HumanMessage) else "assistant" if isinstance(msg, AIMessage) else "system"
        content = msg.content if role != "system" else "[System Prompt Hidden]"
        chat_data.append({"role": role, "content": content})
    with open("chat_history.json", "w", encoding="utf-8") as f:
        json.dump(chat_data, f, indent=4)

# Scoring
def score_answer(analysis):
    return int((analysis['relevance'] + analysis['depth'] + analysis['clarity']) / 3)

def suggest_improvement(analysis):
    suggestions = []
    if analysis['relevance'] < 60: suggestions.append("Improve relevance")
    if analysis['depth'] < 60: suggestions.append("Give deeper explanations")
    if analysis['clarity'] < 60: suggestions.append("Be more clear")
    return suggestions or ["Great response!"]

# Session State
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "poor_answers" not in st.session_state:
    st.session_state.poor_answers = 0
if "scores" not in st.session_state:
    st.session_state.scores = []

# Start Interview
if start_interview and not st.session_state.chat_history:
    st.session_state.chat_history.append(SystemMessage(content=system_prompt(job_role, level)))
    first_msg = AIMessage(content="Hi! I'm Greg, your AI interviewer. Let's begin! Can you briefly introduce yourself?")
    st.session_state.chat_history.append(first_msg)
    save_chat(st.session_state.chat_history)

# Display messages (skip system prompt)
for msg in st.session_state.chat_history:
    if isinstance(msg, SystemMessage):
        continue
    role = "user" if isinstance(msg, HumanMessage) else "assistant"
    st.chat_message(role).markdown(msg.content)

# Input
if prompt := st.chat_input("Your answer"):
    st.chat_message("user").markdown(prompt)
    st.session_state.chat_history.append(HumanMessage(content=prompt))

    # Basic tone check
    if tone_classifier(prompt, ["unclear", "incomplete", "confused", "irrelevant"])['scores'][0] > 0.6:
        st.session_state.poor_answers += 1
    else:
        st.session_state.poor_answers = 0

    if st.session_state.poor_answers >= 3:
        end_msg = "Not ready now ‚Äî no worries. Try again later. Interview Ended."
        st.session_state.chat_history.append(AIMessage(content=end_msg))
        st.chat_message("assistant").markdown(end_msg)
        save_chat(st.session_state.chat_history)
        st.session_state.chat_history.clear()
        st.session_state.poor_answers = 0
        st.stop()

    # Stream response
    with st.spinner("Thinking..."):
        response_stream = llm.stream(st.session_state.chat_history)
        reply = ""
        placeholder = st.empty()
        for chunk in response_stream:
            if chunk.content:
                reply += chunk.content
                placeholder.markdown(reply)

    # Only add reply once
    final_reply = AIMessage(content=reply)
    st.session_state.chat_history.append(final_reply)
    st.chat_message("assistant").markdown(final_reply.content)

    # Analyze answer
    question = next((msg.content for msg in reversed(st.session_state.chat_history[:-1]) if isinstance(msg, AIMessage)), None)
    analysis = analyze_answer(question, prompt)
    score = score_answer(analysis)
    st.session_state.scores.append(score)

    st.markdown("### üß† Answer Feedback")
    st.progress(min(max(score / 100, 0.0), 1.0))
    st.write(f"**Score:** {score}/100")
    st.write(f"**Relevance:** {analysis['relevance']}, **Depth:** {analysis['depth']}, **Clarity:** {analysis['clarity']}")
    st.write(f"**Tone:** {analysis['tone'][0]} (Confidence: {analysis['tone'][1]})")
    st.write(f"**Suggestions:** {' | '.join(suggest_improvement(analysis))}")

    # End interview?
    if "interview ended" in reply.lower():
        st.success("üéâ Interview Ended")
        save_chat(st.session_state.chat_history)
        st.session_state.chat_history.clear()
        st.session_state.poor_answers = 0
        st.session_state.scores.clear()
        st.stop()

    save_chat(st.session_state.chat_history)